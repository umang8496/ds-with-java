
===================
Dynamic Programming
===================
It is mainly an optimization over plain recursion.
Wherever we see a recursive solution that has repeated calls for same inputs, we can optimize it using Dynamic Programming.
The idea is to simply store the results of subproblems, so that we do not have to re-compute them when needed later.
This simple optimization reduces time complexities from exponential to polynomial.

For example, 
	if we write simple recursive solution for Fibonacci Numbers, we get exponential time complexity and 
	if we optimize it by storing solutions of subproblems, time complexity reduces to linear

There are following two different ways to store the values so that the values of a sub-problem can be reused.
Tabulation: Bottom Up
Memoization: Top Down

Differences between Tabulation and Memoization
----------------------------------------------
Tabulation
	State Transition relation is dificult to think
	Codes gets complicated when a lot of conditions are required
	Fast, as we directly access previous state from the table
	If all the subproblems must be solved atleast once, then a bottom-up DP algorithm outperforms a top-down DP algorithm by a constant factor
	Here, starting from the first entry, all entries are filled one by one.

Memoization
	State Transition relation is easy to think
	Code is easy and less complicated
	Slow, due to lot of recursive calls and return statements
	If some subproblems need not be solved at all, then the top-down DP algorithm has advantage over bottom-up DP algorithm.
	Unlike the tabulated version, all entries of the lookup table are not necessarily filled in memoized version.

DP is an algorithmic paradigm that solves a given complex problem by breaking it into subproblems and stores the results of subproblems to avoid computing the same results again.

Following are the two main properties of a problem that suggests that the given problem can be solved using Dynamic programming.
(1) Overlapping Subproblems
	Like Divide and Conquer, Dynamic Programming combines solutions to sub-problems.
	Dynamic Programming is mainly used when solutions of same subproblems are needed again and again.
	
	In dynamic programming, computed solutions to subproblems are stored in a table so that these don’t have to be recomputed.
	So DP is not useful when there are no common (overlapping) subproblems because there is no point storing the solutions if they are not needed again.
	
	For example, Binary Search doesn’t have common subproblems. 
	Whereas, Fibonacci Series has common subproblems.

(2) Optimal Substructure
	A given problems has Optimal Substructure Property if optimal solution of the given problem can be obtained by using optimal solutions of its subproblems.
	
	For example, the Shortest Path problem has following optimal substructure property:
	If a node x lies in the shortest path from a source node u to destination node v then the shortest path from u to v is combination of shortest path from u to x and shortest path from x to v.
	The standard All Pair Shortest Path algorithms like Floyd–Warshall and Bellman–Ford are typical examples of Dynamic Programming.

	On the other hand, the Longest Path problem doesn’t have the Optimal Substructure property.
	Here by Longest Path we mean longest simple path (path without cycle) between two nodes.

